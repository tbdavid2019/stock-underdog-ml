"""
Main entry point for stock prediction application
Uses modular components for cleaner architecture
"""
import datetime
import torch
import pandas as pd
from config import config
from database import SupabaseManager
from data_loader import get_stock_data, download_many, get_tw0050_stocks, get_tw0051_stocks, get_sp500_stocks, get_nasdaq_stocks, get_sox_stocks, get_dji_stocks
from models.lstm import prepare_data, train_lstm_model, predict_stock
from models.transformer import train_transformer_model, predict_transformer
from models.prophet_model import train_prophet_model, predict_with_prophet
from models.chronos_model import prepare_chronos_data, train_and_predict_chronos
from models.cross_section import CROSS_MODELS, import_model, build_cross_xy, train_tabnet, train_cross_loop
from notifier import send_results, send_to_telegram
from logger import logger
from parallel_processor import process_single_stock
from concurrent.futures import ThreadPoolExecutor, as_completed


def get_top_and_bottom_10_potential_stocks(period, selected_indices, db_manager=None):
    """
    ä¾æ‰€é¸æŒ‡æ•¸ï¼Œå›å‚³å„æ¨¡å‹æ½›åŠ›æ’è¡Œæ¦œï¼ˆå‰ / å¾Œ 10ï¼‰
    çµæ§‹ç¯„ä¾‹ï¼š
    {
        "å°ç£50": {
            "ğŸ¥‡ å‰åå LSTM ":    [ (ticker, pot, curr, pred), ... ],
            "ğŸ“‰ å¾Œåå LSTM ":    [ ... ],
            ...
            "ğŸš€ å‰åå TabNet":     [ ... ],
            "â›” å¾Œåå TabNet":     [ ... ]
        }, ...
    }
    """
    results = {}

    # --- æŒ‡æ•¸ â†’ è‚¡ç¥¨æ¸…å–® ---------------------------------
    index_stock_map = {
        "å°ç£50":      get_tw0050_stocks(),
        "å°ç£ä¸­å‹100": get_tw0051_stocks(),
        "SP500":       get_sp500_stocks(),
        "NASDAQ":      get_nasdaq_stocks(),
        "è²»åŸåŠå°é«”":   get_sox_stocks(),
        "é“ç“Š":        get_dji_stocks(),
    }

    # --- å…¨åŸŸè¨­å®š ---------------------------------------
    device = "cuda" if torch.cuda.is_available() else "cpu"

    logger.info(f"\nè¨ˆç®—æ½›åŠ›è‚¡... (Period={period})")

    for index_name, stock_list in index_stock_map.items():
        stock_predictions = {}  # æ¯å€‹æŒ‡æ•¸éƒ½é‡æ–°åˆå§‹åŒ–
        if index_name not in selected_indices:
            continue
        logger.info(f"\n=== è™•ç†æŒ‡æ•¸: {index_name} ===")

        # -------- åºåˆ—æ¨¡å‹å®¹å™¨ --------
        lstm_preds, prophet_preds = [], []
        transformer_preds, chronos_preds = [], []

        # ======== å…ˆè·‘æ©«æ–·é¢æ¨¡å‹ï¼ˆCross Sectional Modelsï¼‰ ========
        if config.use_cross:
            logger.info("å•Ÿå‹• Cross Section ç­–ç•¥...")
            try:
                raw_df = download_many(stock_list, config.cross_period)
                Xc, yc, meta_c = build_cross_xy(raw_df)

                # ä¿®æ­£ mask_last = Series vs Series éŒ¯èª¤
                max_date = pd.Timestamp(meta_c['Date'].max())
                logger.debug(f"[LOG] max_date: {max_date}, type: {type(max_date)}")
                logger.debug(f"[LOG] meta_c['Date'] head: {meta_c['Date'].head()}, dtype: {meta_c['Date'].dtype}")
                mask_last = meta_c['Date'].values == max_date
                logger.debug(f"[LOG] mask_last: {mask_last}, shape: {mask_last.shape}, type: {type(mask_last)}")
                meta_last = meta_c[mask_last].reset_index(drop=True)
                logger.debug(f"[LOG] meta_last shape: {meta_last.shape}, columns: {meta_last.columns}")

                latest_close = (
                    raw_df[raw_df['Date'] == max_date]
                    .groupby('Ticker')['Close']
                    .first()
                )
                logger.debug(f"[LOG] latest_close index: {latest_close.index}, type: {type(latest_close)}")

                # åŸ·è¡Œ Cross æ¨¡å‹ï¼ˆTabNetï¼ŒSFMï¼ŒADDModelï¼‰
                for m_path, cls_list in CROSS_MODELS:
                    ModelClass = import_model(m_path, cls_list)
                    if ModelClass is None:
                        continue
                    logger.info(f"ğŸ” Cross è¨“ç·´ {ModelClass.__name__} â€¦")
                    try:
                        if ModelClass.__name__ == "TabNet":
                            preds_all = train_tabnet(Xc, yc, epochs=config.cross_epochs, device=device)
                        else:
                            preds_all = train_cross_loop(ModelClass, Xc, yc, config.cross_epochs, device)
                        logger.debug(f"[LOG] preds_all shape: {getattr(preds_all, 'shape', None)}, type: {type(preds_all)}")
                        preds_last = preds_all[mask_last]
                        logger.debug(f"[LOG] preds_last shape: {getattr(preds_last, 'shape', None)}, type: {type(preds_last)}")

                        # çµ„ TabNet / SFM / ADDModel çµæœ
                        records = [
                            (
                                tic,
                                p,                               # é æ¸¬æ½›åŠ›
                                float(latest_close[tic]),        # ç¾åƒ¹
                                float(latest_close[tic] * (1+p)) # é æ¸¬åƒ¹
                            )
                            for tic, p in zip(meta_last['Ticker'], preds_last)
                        ]
                        logger.debug(f"[LOG] records sample: {records[:3]}")

                        # å¯« Databse (Supabase)
                        if db_manager and db_manager.enabled:
                            db_manager.save_predictions(index_name, records, ModelClass.__name__, config.cross_period)
                        else:
                            logger.info("DB Manager not initialized or enabled.")

                        # æ’è¡Œæ¦œ
                        stock_predictions.update({
                            f"ğŸš€ å‰äº”å {ModelClass.__name__}": sorted(records, key=lambda x:x[1], reverse=True)[:5],
                            f"â›” å¾Œäº”å {ModelClass.__name__}": sorted(records, key=lambda x:x[1])[:5],
                        })
                        logger.debug(f"[DEBUG] stock_predictions keys after update: {list(stock_predictions.keys())}")
                        logger.debug(f"[DEBUG] stock_predictions lens after update: {[len(v) for v in stock_predictions.values()]}")

                        if len(preds_last) == 0:
                            logger.warning(f"{ModelClass.__name__} æ²’æœ‰ç”¢ç”Ÿé æ¸¬çµæœ")
                            continue

                    except Exception as e:
                        logger.error(f"{ModelClass.__name__} å¤±æ•—: {e}")
                        continue

            except Exception as e:
                logger.error(f"Crossâ€‘section æµç¨‹éŒ¯èª¤: {e}")

        # ======== è·‘æ™‚é–“åºåˆ—æ¨¡å‹ (Parallel) ========
        logger.info(f"å•Ÿå‹•ä¸¦è¡Œè™•ç† (Max Workers: 5)... åˆ†æ {len(stock_list)} æ”¯è‚¡ç¥¨")
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_stock = {executor.submit(process_single_stock, tic, period): tic for tic in stock_list}
            
            for future in as_completed(future_to_stock):
                tic = future_to_stock[future]
                try:
                    res = future.result()
                    if 'lstm' in res: lstm_preds.append(res['lstm'])
                    if 'transformer' in res: transformer_preds.append(res['transformer'])
                    if 'prophet' in res: prophet_preds.append(res['prophet'])
                    if 'chronos' in res: chronos_preds.append(res['chronos'])
                    
                    # Optional: Progress logging
                    # print(f"å®Œæˆ: {tic}")
                except Exception as e:
                    logger.error(f"è™•ç†å¤±æ•— {tic}: {e}")

        # --- Databaseï¼šæ™‚é–“åºåˆ—æ¨¡å‹ ---------------------------
        if db_manager and db_manager.enabled:
            if lstm_preds:
                db_manager.save_predictions(index_name, lstm_preds, "LSTM", period)
            if config.use_prophet and prophet_preds:
                db_manager.save_predictions(index_name, prophet_preds, "Prophet", period)
            if config.use_transformer and transformer_preds:
                db_manager.save_predictions(index_name, transformer_preds, "Transformer", period)
            if config.use_chronos and chronos_preds:
                db_manager.save_predictions(index_name, chronos_preds, "Chronos-Bolt", config.chronos_period)

        # --- çµ„æ’è¡Œæ¦œï¼ˆæ™‚é–“åºåˆ—ï¼‰ -------------------------
        stock_predictions = stock_predictions if 'stock_predictions' in locals() else {}

        stock_predictions.update({
            "ğŸ¥‡ å‰äº”å LSTM ğŸ§ ": sorted(lstm_preds, key=lambda x: x[1], reverse=True)[:5],
            "ğŸ“‰ å¾Œäº”å LSTM ğŸ§ ": sorted(lstm_preds, key=lambda x: x[1])[:5],
        })
        if config.use_prophet and prophet_preds:
            stock_predictions.update({
                "ğŸš€ å‰äº”å Prophet ğŸ”®": sorted(prophet_preds, key=lambda x: x[1], reverse=True)[:5],
                "â›” å¾Œäº”å Prophet ğŸ”®": sorted(prophet_preds, key=lambda x: x[1])[:5],
            })
        if config.use_transformer and transformer_preds:
            stock_predictions.update({
                "ğŸš€ å‰äº”å Transformer ğŸ”„": sorted(transformer_preds, key=lambda x: x[1], reverse=True)[:5],
                "â›” å¾Œäº”å Transformer ğŸ”„": sorted(transformer_preds, key=lambda x: x[1])[:5],
            })
        if config.use_chronos and chronos_preds:
            stock_predictions.update({
                "ğŸš€ å‰äº”å Chronos-Bolt âš¡": sorted(chronos_preds, key=lambda x: x[1], reverse=True)[:5],
                "â›” å¾Œäº”å Chronos-Bolt âš¡": sorted(chronos_preds, key=lambda x: x[1])[:5],
            })

        # -------- æ”¶å°¾ --------
        if stock_predictions:
            results[index_name] = stock_predictions

    return results


def main():
    """Main execution function"""
    try:
        # Initialize Database manager (Supabase)
        db_manager = SupabaseManager()

        calculation_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        period = "6mo"
        selected_indices = ["å°ç£50", "å°ç£ä¸­å‹100", "SP500"]

        print("è¨ˆç®—æ½›åŠ›è‚¡...")
        analysis_results = get_top_and_bottom_10_potential_stocks(period, selected_indices, db_manager)

        # Process and send results for each index separately
        for index_name, stock_predictions in analysis_results.items():
            print(f"è™•ç†ä¸¦ç™¼é€çµæœ: {index_name}")
            send_results(index_name, stock_predictions)

    except Exception as e:
        print(f"éŒ¯èª¤: {str(e)}")
        send_to_telegram(f"âš ï¸ éŒ¯èª¤: {str(e)}")

    finally:
        # Close DB connection if needed
        pass
        

if __name__ == "__main__":
    main()
